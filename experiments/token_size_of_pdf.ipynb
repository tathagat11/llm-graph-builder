{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cac539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Analysis for: ramayana-english.pdf\n",
      "Total Pages: 1960\n",
      "Total Words: 418954\n",
      "Total Tokens: 656550\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import tiktoken\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "genai_client = genai.Client(vertexai=True, project=\"trim-sunlight-412311\", location=\"global\")\n",
    "\n",
    "def count_pdf_tokens(file_path: str) -> (int, int, int):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF and calculates the total number of tokens, words, and pages.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the total token count, word count, and page count.\n",
    "        Returns (0, 0, 0) if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at '{file_path}'\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        doc = fitz.open(file_path)\n",
    "        page_count = doc.page_count\n",
    "        full_text = \"\"\n",
    "\n",
    "        # Extract text from each page\n",
    "        for page_num in range(page_count):\n",
    "            page = doc.load_page(page_num)\n",
    "            full_text += page.get_text()\n",
    "        \n",
    "        doc.close()\n",
    "\n",
    "        token_count = genai_client.models.count_tokens(model = \"gemini-2.5-pro\", contents=full_text).total_tokens\n",
    "        \n",
    "        word_count = len(full_text.split())\n",
    "\n",
    "        return token_count, word_count, page_count\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "pdf_path = \"/home/tathagat/workspace/projects/StoryDarpan/llm-graph-builder/experiments/ramayana-english.pdf\"\n",
    "\n",
    "tokens, words, pages = count_pdf_tokens(pdf_path)\n",
    "    \n",
    "if tokens > 0:\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Analysis for: {os.path.basename(pdf_path)}\")\n",
    "    print(f\"Total Pages: {pages}\")\n",
    "    print(f\"Total Words: {words}\")\n",
    "    print(f\"Total Tokens: {tokens}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
